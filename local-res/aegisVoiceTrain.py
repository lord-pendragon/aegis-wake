# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eptFFyGfhop7kUbN4nnaiE9uWW7WRWMi
"""

from pathlib import Path
# use the SAME path that worked for you:
RAW_ROOT = Path("content/dataset")      # your m4a files live here
WAV_ROOT = Path("/content/oww_wav")     # converted wav cache
SR = 16_000

# CELL 1 — load frames
from pathlib import Path
from itertools import chain
import numpy as np, librosa

SR = 16_000
DATA_ROOT = Path("/content/oww_wav")   # <-- this is where your converted WAVs are

def load(path):
    y,_ = librosa.load(str(path), sr=SR, mono=True)
    m = np.max(np.abs(y));
    if m>0: y = y/m
    return y.astype(np.float32)

def frames(y, win=SR, hop=SR//2):
    if len(y)<win:
        y=np.pad(y,(0,win-len(y)))
        return [y[:win]]
    return [y[i:i+win] for i in range(0, len(y)-win+1, hop)]

X, yL = [], []

# positives -> 1
for p in sorted((DATA_ROOT/"positives").rglob("*.wav")):
    for f in frames(load(p)): X.append(f); yL.append(1)

# negatives (confusables + background) -> 0   (no '+' on generators; use chain)
for p in chain((DATA_ROOT/"confusables").rglob("*.wav"),
               (DATA_ROOT/"background").rglob("*.wav")):
    for f in frames(load(p)): X.append(f); yL.append(0)

X = np.array(X)[..., None]  # [N,16000,1]
yL = np.array(yL)
print("Frames:", X.shape, "| Pos:", int(yL.sum()), "| Neg:", int((yL==0).sum()))

# CELL 2 — train
import tensorflow as tf
from sklearn.model_selection import train_test_split

Xtr, Xval, ytr, yval = train_test_split(X, yL, test_size=0.15, stratify=yL, random_state=42)

inp=tf.keras.Input(shape=(16000,1))
x=tf.keras.layers.Conv1D(16,9,strides=2,padding="same",activation="relu")(inp)
x=tf.keras.layers.BatchNormalization()(x)
x=tf.keras.layers.SeparableConv1D(32,9,strides=2,padding="same",activation="relu")(x)
x=tf.keras.layers.BatchNormalization()(x)
x=tf.keras.layers.SeparableConv1D(64,9,strides=2,padding="same",activation="relu")(x)
x=tf.keras.layers.BatchNormalization()(x)
x=tf.keras.layers.GlobalAveragePooling1D()(x)
x=tf.keras.layers.Dropout(0.25)(x)
out=tf.keras.layers.Dense(1,activation="sigmoid")(x)
model=tf.keras.Model(inp,out)
model.compile(optimizer="adam", loss="binary_crossentropy",
              metrics=["accuracy", tf.keras.metrics.AUC(name="auc")])

pos = int(yL.sum()); neg = len(yL)-pos
class_weight = {0: 1.0, 1: max(1.0, neg/pos)}  # balances ~Pos:Neg

cb=[tf.keras.callbacks.EarlyStopping(monitor="val_auc", patience=5, mode="max", restore_best_weights=True)]
model.fit(tf.data.Dataset.from_tensor_slices((Xtr,ytr)).shuffle(8192).batch(64).prefetch(4),
          validation_data=tf.data.Dataset.from_tensor_slices((Xval,yval)).batch(64),
          epochs=30, callbacks=cb, verbose=1, class_weight=class_weight)

# CELL 3 — export
# float32
conv = tf.lite.TFLiteConverter.from_keras_model(model)
open("/content/aegis_oww.tflite","wb").write(conv.convert())
print("saved: /content/aegis_oww.tflite")

# (optional) int8
def rep_ds():
    for i in range(min(200,len(Xtr))):
        yield [Xtr[i:i+1]]
conv = tf.lite.TFLiteConverter.from_keras_model(model)
conv.optimizations=[tf.lite.Optimize.DEFAULT]
conv.representative_dataset=rep_ds
conv.target_spec.supported_ops=[tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
conv.inference_input_type=tf.int8
conv.inference_output_type=tf.int8
open("/content/aegis_oww_int8.tflite","wb").write(conv.convert())
print("saved: /content/aegis_oww_int8.tflite")